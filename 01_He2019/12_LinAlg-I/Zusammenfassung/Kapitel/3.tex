\mdfsetup{backgroundcolor=orange!20}
\begin{mdframed}
\textbf{Quotientenräume:}\quad Sei $V$ ein $K$-Vektorraum, $U \subseteq V$ ein Untervektorraum. Für $v, v' \in V$ definieren wir die Äquivalenz modulo $u$: $v \sim_U v' \Leftrightarrow v-v' \in U$.\\
Für einen Vektor $v \in V$ ist die Äquivalenzklasse $[v]_{\sim_U}$ ein affiner Raum. 
\begin{align*}
    [v]_{\sim_u} = \{v' \in V \big\vert v' \sim_u V\} = v + U
\end{align*}
Die Menge der Äquivalenzklassen $V_{/U} = \{[v]_{\sim_U} \big\vert v \in V\} = \{v + U \big\vert v \in V\}$ heisst \textbf{Quotientenraum}
\end{mdframed}
Die \textbf{kanonische Abbildung} sei $\rho: V \rightarrow V_{/U}, v \mapsto v + U$\\
\textbf{Satz} Sei $V$ ein $V$-Vektorraum, $U$ ein Untervektorraum von $V$. Dann kann man $V_{/U}$ auf genau eine Weise so zu einem $K$-Vektorraum machen, dass die Kanonische Abbildung $\rho: V \rightarrow V_{/U}$ linear wird.
\begin{enumerate}[{(}1{.)}]
    \item	$\rho$ ist surjektiv
    
    \item $\Kernel \rho = U$
    
    \item $\dim \left(V_{/U}\right) = \dim V - \dim U$ (Für $V$ endlich dimensional.)
    
    \item $V_{/U}$ hat die \textbf{universelle Eigenschaft:}\\
    Ist $F: V \rightarrow W$ linear mit $U \subseteq \Kernel F$, so gibt es \underline{genau eine} lineare Abbildung $\overline{F}: V_{/U} \rightarrow W$ mit $F = \overline{F} \circ \rho$\\
    %\begin{tikzcd}[]
    %   $V$ & $W$\\
    %   $V_{/U}$ 
    %\end{tikzcd}
    Weiter ist $\Kernel \overline{F} = \left(\Kernel F\right)_{/U}$ und Addition bzw. Multiplikation in $\overline{F}$ wohldefiniert. (Unabhängig von der Wahl des Repräsentanten.) 
\end{enumerate}
\textbf{Satz} Sei $V = V_1 \oplus V_2$ und $\rho: V \rightarrow V_{/V_2}$ die kanonische Abbildung. Dann ist $\rho':= \rho |_{V_1}: V_1 \rightarrow V_{/V_2}$ Iso.\\

\newpage
\section{Transformationen \& Matrizen}
\mdfsetup{backgroundcolor=orange!20}
\begin{mdframed}
Betrachte $A = (a_{ij}) \in M(m\times n,K)$ und $b = \begin{pmatrix}
b_{1} \\ \vdots \\	 b_{m}
\end{pmatrix} \in M(m\times 1,K)$
\begin{align*}
    (*): \quad A\cdot x = b \Leftrightarrow \summe{j = 1}{n} a_{ij}x_j = b_i, \forall i \in \{1, \ldots m\}
\end{align*}
man nennt $A \cdot x = 0$ das zu $(*)$ gehörige \textbf{homogene System}. Ist $b \neq 0$, so ist $(*)$ \textbf{inhomogen}.\quad 
Die Menge $\text{Lös}(A,b) = \{x \in K^n \big\vert A \cdot x  = b\}$ heisst \textbf{Lösungsraum}.
\end{mdframed}
Bezeichnung zu der durch $A$ definierten Linearen Abbildung: $L_A = A = F_A : K^n \rightarrow K^m, x \mapsto A\cdot x$ ist $\textbf{Lös}(A,b) = L_A^{-1}(b) =$ Faser über b. Ist $b = 0$, so ist $\text{Lös}(A,b) = \Kernel L_A$\\
Diese zugehörige Lineare Abbildung vererbt den Rangbegriff der Matrix: $r = \rang L_A := \rang A$\\
\textbf{Korollar}: 
\begin{enumerate}[{(}1{.)}]
    \item	$\textbf{Lös}(A,0)$ ist ein Untervektorraum der Dimension $n-r$.
    
    \item $\textbf{Lös}(A,b)$ ist ein affiner Raum der Dimension $n-r$. Ist $v \in \textbf{Lös}(A,b)$ belibig, so gilt:
    \mdfsetup{backgroundcolor=orange!20}
    \begin{mdframed}
        \begin{align*}
            \textbf{Lös}(A,b) &= v + \textbf{Lös}(A,0)\\
            \text{Allgemeine Lösung } &= \text{partikuläre Lösung } + \text{ homogene Lösung}
        \end{align*}
    \end{mdframed}    
\end{enumerate}
\textbf{Satz} $\text{Lös}(A,b) \neq 0 \Leftrightarrow \rang A = \rang (A,b)$\\
\textbf{Satz} Sei $(A,b)$ in Zeilen-Stufen-Form, $\rang A = r, b \in K^m$. Dann hat die Parametrisierung $\Phi_b: K^{n-r} \rightarrow \text{Lös}(A,b) \subseteq K^n$ folgende Eigenschaften
\begin{enumerate}[{(}1{.)}]
    \item	$\Phi_0: K^{n-r} \rightarrow \Kernel A$ ist Iso.
    
    \item $\Phi_b: K^{n-r} \rightarrow \text{Lös}(A,b)$ ist  bijektiv
    
    \item Es gibt einen homomorphismus $\phi: K^r \rightarrow K^n$, sodass $\forall b \in K^n$ gilt
    \begin{align*}
        \Phi_b = \phi(b) + \Phi_0 \text{ mit } \text{Lös}(A,b) = \phi(b) + \text{Lös}(A,b)
    \end{align*}
\end{enumerate}
Sucht man die allgemeine Lösung eines linearen Gleichugnssystems, so ist die Parametrisierung wie folgt gegeben:
\begin{align*}
    \Phi_b \begin{pmatrix}
    \lambda_{1} \\ \vdots \\	 \lambda_{k}
    \end{pmatrix} = D \cdot \begin{pmatrix}
    b_{1} \\ \vdots \\	 b_{m}
    \end{pmatrix}
    + C \cdot \begin{pmatrix}
    \lambda_{1} \\ \vdots \\	 \lambda_{k}
    \end{pmatrix}
\end{align*}
wobei $d_{ij}$ Koeffizienten von $b_j$ bei $x_i$ sind und $c_{ij}$ die Koeffizienten von $\lambda_i$ bei $x_i$ sind. Die Spalten von $C$ werden \textbf{Fundamentalsystem} (Basis von $\text{Lös}(A,0))$ genannt und $D \cdot b$ ist eine partikuläre Lösung.\\
\textbf{Spezialfälle:} Sei $A \in M(m\times n,K), b \in K^m$, so sind äquivalent:
\begin{enumerate}[{(}i{)}]
    \item Das Lineare Gleichungsystem hat genau eine Lösung
    
    \item $\rang A = \rang (A,b) = n$
\end{enumerate}
Falls $m = n$, ist die eindeutige Lösung $x = A^{-1}\cdot b$ und $A \cdot x = 0$ hat nur die triviale Lösung $x = 0$. \\
Ist $\rang A = m$, so ist $A: K^m \rightarrow K^m$ surjektiv und $\text{Lös}(A,b)$ ist nicht-leer für alle $b \in K^m$\\
\mdfsetup{backgroundcolor=black!10}
\begin{mdframed}
\textbf{Satz} \quad Seien $V, W$ endlich Dimensionale $K$-Vektorräume und $v_1, \ldots, v_n \in V, w_1, \ldots, w_n \in W$, dann gilt
\begin{enumerate}[{(}1{.)}]
    \item	Sind $v_1, \ldots, v_n$ linear unabhängig, so gibt es mindestens eine Lineare Abbildung $F: V \rightarrow W$ mit $F(v_i) = w_i$
    
    \item Ist $(v_1, \ldots, v_n)$ eine Basis von $V$, so ist dieses $F$ eindeutig bestimmt und es erfüllt:
    \begin{enumerate}[{(}a{)}]
        \item $\Image F = \spn(w_1, \ldots, w_n)$
        
        \item $F$ injektiv $\Leftrightarrow w_1, \ldots, w_n$ sind linear unabhängig. 
    \end{enumerate}
\end{enumerate}
\end{mdframed}
\textbf{Korollar}
\begin{enumerate}[{(}a{)}]
    \item Hat $V$ eine Basis $B = (v_1, \ldots, v_n)$, so gibt es genau einen Isomorphismus $\Phi_B: K^n \rightarrow V$ mit $\Phi_B(e_i) = v_i$
    
    \item Zu jeder Linearen Abbildung $F: K^n \rightarrow K^m$ gibt es genau eine Matrix $A \in M(m\times n,K)$ sodass $F(x) = A \cdot x, \forall x \in K^n$ und $A = \begin{pmatrix}
    | &  & |\\
    F(e_1) & \ldots & F(e_n)\\
    | & & |
    \end{pmatrix}$
\end{enumerate}
\textbf{Satz} (Matrizendarstellung von Linearen Abbildungen)\\
Gebeben seien zwei $K$-Vektorräume $V,W$ mit jeweiliger Basis $A = (v_1, \ldots, v_n) \subseteq V$, $B = w_1, \ldots, w_m) \subseteq W$. Dann gibt es zu jeder linearen Abbildung $F \in \text{Hom}_K(V,W)$ eine Matrix $A = \left(a_{ij}\right) \in M(m\times n,K)$ sodass $F(v_j) = \summe{i = 0}{m} a_{ij}w_j$\\
Man drückt $F(v_j)$ durch die Vektoren $w_1, \ldots, w_m$ aus und schreibt die Koeffizienten der Linearkombination in der $j$-ten Spalte von $A$ auf.
\begin{align*}
    A = \begin{pmatrix}
    | &  & |\\
    [F(v_1)]_B & \ldots & [F(v_n)]_B\\
    | & & |
    \end{pmatrix}
    \qquad  [\cdot]_B = \Phi_B^{-1}
\end{align*}
die so erhaltene Abbildung $M_{B}^{A}: \text{Hom}(V,W) \rightarrow M(m\times n,K), F \mapsto A = M_{B}^{A}(F)$ ist iso.\\
$M_{B}^{A}$ ist die Darstellungsmatrix von $F$ bezüglich den Basen $A$ und $B$.\\
Sei dazu $F_{i}^{j}: V \rightarrow W$ durch 
\begin{align*}
    F_{i}^{j}(v_k) := \begin{cases}
        w_i, \quad \text{ für } k = j\\
        0, \quad \text{ sonst }
    \end{cases}
    \quad \text{ also } F_{i}^{j}(v_k)  = \delta_{kj} w_i
\end{align*}
Dann ist $M_{B}^{A}(F_{i}^{j}) = E_{ij} =$ die Matrix mit $1$ in $i-j$-ten Einträgen.\\
Die $m \cdot n$ vielen Abbildungen bilden eine Basis von $\text{Hom}(V,W)$.\\
\textbf{Korollar} Sei $F: V \rightarrow W$ linear, $\dim V = n, \dim W = m, r = \rang F$.\\
Dann gibt es Basen $A$ und $B$, sodass $M_{B}^{A}(F) = \begin{pmatrix}
    E_r & 0\\
    0 & 0
\end{pmatrix}$ die Normalform annimmt.\\
\textbf{Lemma} Ist $A \in M(m\times n,K), B \in M(n\times r,K)$, so gilt
\begin{align*}
    \rang A + \rang B -n \leq \rang A \cdot B \leq \min\{\rang A, \rang B\}
\end{align*}
\mdfsetup{backgroundcolor=orange!20}
\begin{mdframed}
Seien $A \in M(m\times n,K)$ und $B \in M(n\times r,K)$. Dann hat das \textbf{Matrizenprodukt} $(c_{ij})$ die Einträge
\begin{align*}
    \times: M(m\times n,K) \times M(n\times r,K) &\rightarrow M(m\times r,K)\\
    A \times B &\mapsto C, \text{ mit } c_{ij} &= \summe{k = 1}{n} a_{ik}\cdot b_{kj}
\end{align*}
Eine Matrix $A \in M(n\times n,K)$ ist \textbf{invertierbar} wenn es eine Matrix $A^{-1} \in M(n\times n,K)$ gibt, mit $A \cdot A^{-1} = A^{-1} \cdot A = E_n$
\end{mdframed}
Die Menge aller invertierbaren $n \times n$ Matrizen: $GL(n,K)$ ist zusammen mit der Matrizenmultiplikation $\cdot$ eine Gruppe und es gilt ${(A^T)}^{-1} = ({A}^{-1})^T$.\\
Es sind äquivalent:
\begin{enumerate}[{(}i{)}]
    \item $A$ ist invertierbar
                                         
    \item $A^T$ ist invertierbar
    
    \item $n =$ Spaltenrang
    
    \item $n = \text{ZR}(A)$
\end{enumerate}
\mdfsetup{backgroundcolor=orange!20}
\begin{mdframed}
\textbf{Koordinatentransformation}: \quad Sei $V$ ein $K$-Vektorraum mit Basis $A = (v_1, \ldots, v_n)$ und $\Phi_A: K^n \rightarrow V, \quad (x_1, \ldots, x_n) \mapsto x_{1} v_{1} + \ldots + x_{n} v_{n}$.\\
Man nennt $\Phi_A^{-1}(v) = (x_1, \ldots, x_n) \in K^n$ die \textbf{Koordinaten} von $v = x_{1} v_{1} + \ldots + x_{n} v_{n} \in V$ bezüglich $A$.\\
Sei $B = (w_1, \ldots, w_n)$ eine weitere Basis von $V$. Dann ist die \textbf{Transformationsmatrix} (des Basiswechsels von $A$ nach $B$) $T_{B}^{A}: K^n \rightarrow K^n = {\Phi_B}^{-1} \circ \Phi_A$
\begin{center}
    \begin{tikzcd}[]
        K^n_A\arrow{dr}{\Phi_A} \arrow[swap]{dd}{\Phi_B^{-1}\cdot \Phi_A =: T_{B}^{A}}& \\
        & V\\
        K^n_B \arrow[swap]{ur}{\Phi_B}&
    \end{tikzcd}
\end{center}
Ist $v = x_{1} v_{1} + \ldots + x_{n} v_{n} = y_{1} w_{1} + \ldots + y_{n} w_{n}$, so gilt
\begin{align*}
    \begin{pmatrix}
    y_{1} \\ \vdots \\	 y_{n}
    \end{pmatrix} = T_{B}^{A} \cdot \begin{pmatrix}
    x_{1} \\ \vdots \\	 x_{n}
    \end{pmatrix}
\end{align*}
\end{mdframed}
Analog, falls $w_j = s_{1j} v_{1} + \ldots + s_{nj} v_{n}$ und $s_i = (s_{ij}) \in M(n\times n,K)$, dann gilt $\Phi_B = \Phi_A \circ S$, daraus folgt
\begin{align*}
    S = {\Phi_A}^{-1} \circ \Phi_B = {T_{B}^{A}}^{-1} = T_{A}^{B}, \quad \text{bzw. } T_{B}^{A} = {S}^{-1}
\end{align*}
\vspace{40pt}
\mdfsetup{backgroundcolor=black!10}
\begin{mdframed}
Sei $F: V \rightarrow W$ linear, $A, B$ Basen, dann kommutiert folgendes Diagramm und es gilt:
\begin{align*}
    \Phi_B \circ M_{B}^{A}(F) = F \circ \Phi_A, \quad \text{also } M_{B}^{A}(F) = {\Phi_B}^{-1} \circ F \circ \Phi_A
\end{align*}
\begin{center}
    \begin{tikzcd}[]
        K^n \arrow[]{r}{\Phi_A} \arrow[swap]{d}{M_{B}^{A}(F)}& V \arrow[]{d}{F}\\
        K^m \arrow[]{r}{\Phi_B}& W
    \end{tikzcd}
\end{center}
$M_{B}^{A}$ ist die Verallgemeinerte Form der Transformationsmatrix, da falls $V = W$, $F = \text{id}$ ist und somit $M_{B}^{A}(\text{id}_V) = T_{B}^{A}$
\end{mdframed}

\textbf{Satz}\quad Seien $U,V,W$ $K$-Vektorräume mit jeweiligen Basen $A,B,C$ und seien $G: U \rightarrow V, F: V \rightarrow W$ linear. Dann gilt
\begin{align*}
    M_{C}^{A}(F \circ G) = M_{C}^{B}(F) \cdot M_{B}^{A}(G)
\end{align*}
und folgendes Diagramm kommutiert.
\begin{center}
    \begin{tikzcd}[] %\arrow[bend right,swap]{dr}{F}
        K^r \arrow[]{r}{\Phi_A} \arrow[]{d}{M_{B}^{A}(G)} \arrow[bend right, swap]{dd}{M_{C}^{A}(F \circ G)}
        &
        U \arrow[swap]{d}{G} \arrow[bend left]{dd}{F \circ G} \\
        K^m \arrow[]{r}{\Phi_B} \arrow[]{d}{M_{C}^{B}(F)}
        &
        V \arrow[swap]{d}{F}\\
        K^n \arrow[swap]{r}{\Phi_C}
        &
        W
    \end{tikzcd}
\end{center}
\mdfsetup{backgroundcolor=orange!20}
\begin{mdframed}
\textbf{Transformationsformel}: \quad Ist $F: V \rightarrow W$ linear, $A, A'$ Basen von $V$, $B,B'$ Basen von $W$, so kommutiert das Diagramm
\begin{center}
    \begin{tikzcd}[] %\arrow[bend right,swap]{dr}{F}
        K^n \arrow[]{r}{M_{B}^{A}(F)} \arrow[bend right, swap]{dd}{T_{A'}^{A}} \arrow[]{d}{\Phi_A} & K^m \arrow[swap]{d}{\Phi_B} \arrow[bend left]{dd}{T_{B'}^{B}} \\
        V \arrow[]{r}{F} & W \\
        K^n \arrow[swap]{u}{\Phi_{A'}} \arrow[]{r}{M_{B'}^{A'}} & K^m \arrow[]{u}{\Phi_{B'}}
    \end{tikzcd}
\end{center}
\begin{align*}
    M_{B'}^{A'}(F) &= T_{B'}^{B} \cdot M_{B}^{A}(F) \cdot {T_{A'}^{A}}^{-1}\\
    {[F]}_{B'}^{A'} &= [\id_W]_{B'}^{B} \cdot [F]_{B}^{A} \cdot [\id_V]_{A}^{A'}
\end{align*}
\end{mdframed}
Zwei Matrizen heissen \textbf{äquivalent} wenn es $S \in GL(m,K), T \in GL(n,K)$ gibt, sodass $B = S A {T}^{-1}$ (Bildet auch eine Äquivalenzrelation)\\
Ist $B$ in Normalform, so findet man $S$ durch Zeilenumformung von $(\mathds{1}_m,A)$ und $T$ durch Spaltenumformung von $(A, \mathds{1}_n)$
Zwei Matrizen heissen \textbf{ähnlich}, wenn es ein $S \in GL(m,K)$ gibt, sodass $B = S A {S}^{-1}$.\\
\textbf{Lemma} $2$ Matrizen sind äquivalent, wenn $\rang A = \rang B$. Und jede Matrix mit $\rang A = n$ ist äquivalent zu $\begin{pmatrix}
    E_r & 0 \\ 0 & 0
\end{pmatrix}$
Die Matrizen in Normalform repräsentieren die Äquivalenzklassen.\\
\textbf{Satz} Jede invertierbare Matrix ist das Produkt von endlich vielen Elementarmatrizen, d.h. die Elementarmatrizen erzeugen $GL(n,K)$\\
\mdfsetup{backgroundcolor=orange!20}
\begin{mdframed}
Die $m$-reihigen \textbf{Elementarmatrizen} sind definiert wie folgt:

\begin{align*}
    S_i(\lambda) = \begin{pmatrix}
        1 & &\\
        & \lambda_{i,i} & \\
        & &  1
    \end{pmatrix}
    \quad Q_{i}^{j}(\lambda) = \begin{pmatrix}
        1 & & & &\\
        & 1 & & \lambda_{ij}  & &\\
        & & \ddots &  &\\
        & & & 1 &\\
        & & & & 1
    \end{pmatrix} \quad 
    P_{i}^{j} = \begin{pmatrix}
        1 & & & & \\
        & 0_{ii} & \ldots & 1_{ij} & \\
        & \vdots & 1 & \vdots & \\
        & 1_{ji} & \ldots & 0_{jj} & \\
        & & & & 1
    \end{pmatrix}
\end{align*}
\begin{itemize}
    \item $S_i(\lambda) =$ Multiplikation der $i$-ten Zeile mit $\lambda$.
    
    \item $Q_{i}^{j}(\lambda) =$ Addition des $\lambda$-fachen der $j$-ten Zeile zur $i$-ten Zeile.
    
    \item $P_{i}^{j} =$ Vertauschung der $i$-ten und $j$-ten Zeile.
    
    \item Multiplikation von links ergibt \textbf{Zeilen}-Umformungen. Multiplikation von rechts ergibt \textbf{Spalten}-Umformungen.
\end{itemize}
\end{mdframed}
