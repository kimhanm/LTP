\section{Dualität und Skalarprodukt}

\begin{definition}{Nicht ausgeartete Bilinearformen}
    Seien $V,W$ $K$-Vektorräume, $b: V \times W \to K$ eine Bilinearform. Betrachte die Abbildungen
    \begin{align*}
        b': V \to W^*, \quad v \mapsto b(v,-) \quad \text{und} \quad b'': W \to V^*, \quad w \mapsto b(-,w)
    \end{align*}
    Dann heisst $b$ \textbf{nicht ausgeartet}, falls $b'$ und $b''$ injektiv sind.
\end{definition}
Es gilt dann 
\begin{enumerate}
    \item	$b: V \times W \to K$ bilinear $\Leftrightarrow b(v,-)$ und $b(-,w)$ linear für alle $v \in V, w \in W$.
    \item   Ist $b$ nicht ausgeartet, so sind $b', b''$ Isomorphismen, da gilt $\dim V \leq \dim W^* = \dim W \leq \dim V^* = \dim V$. 
    \item   
    \begin{align*}
        b \text{ nicht ausgeartet } \Leftrightarrow &\forall v \neq 0 \in V \exists w \in W: b(v,w) \neq 0 \quad \text{und} \quad
        &\forall w \neq 0 \in W \exists v \in V: b(v,w) \neq 0    
    \end{align*}
\end{enumerate}


\begin{definition}{Kanonischer Isomorphismus von Dualraum}
    Sei $V$ ein euklidischer Vektorraum. Der \textbf{Kanonische Isomorphismus} zwischen $V$ und $V^*$ ist die Abbildung
    \begin{align*}
        \Phi: V \to V^* \quad v \mapsto \left<-,v\right>
    \end{align*}
\end{definition}
Es gilt dann
\begin{enumerate}
    \item	Für jeden UVR $U \subseteq V$ ist gilt
    \begin{align*}
        \Phi(U^{\bot}) = U^{0}
    \end{align*}
    \item   Ist $\mathcal{B} = (v_{1}, \ldots, v_{n})$ eine ONB von $V$ und $\mathcal{B}^* = (v_{1}^*, \ldots, v_{n}^*)$ die duale Basis, so ist $\psi(v_i) = v_i^*$
\end{enumerate}

\textbf{Bemerkung:} \quad Für Sesquilinearformen auf $\C$-Vektorräumen ist $s'': v \mapsto s(-,v)$ nur semilinear und man erhält einen Semi-Isomorphismus: d.h. $\Phi(\lambda v) = \overline{\lambda}\Phi(v)$
\begin{align*}
    \Phi: V \to V^*, \quad v \mapsto \left<-,v\right>
\end{align*}



\section{Adjungierte Abbildungen}
\begin{definition}{Adjungierte Abbildungen}
    Seien $V,W$ in euklidische/unitäre $K$-Vektorräume. $F: V \to W$ linear. Dann ist die zu $F$ \textbf{adjungierte Abbildung} $F^{ad}$ die Abbildung charakterisiert durch
    \begin{align*}
        \left<F(v),w\right>_{W} = \left<v,F^{ad}(w)\right>_{V}, \forall v \in W, w \in W \tag{$\ast$}
    \end{align*}
\end{definition}
Es gilt dann
\begin{enumerate}
    \item	Falls $F^{ad}$ existiert, so ist sie eindeutig und es gilt ${F^{ad}}^{ad} = F$
    \item   Mit den kanonischen Isomorphismen $\Phi: V \to V^*, \Psi: W \to W^*$ gilt $F^{\ad} = \Phi^{-1} \circ F^* \circ \Psi$.
    \begin{center}
        \begin{tikzcd}[] %\arrow[bend right,swap]{dr}{F}
            V \arrow[]{d}{\Phi} & \arrow[swap]{l}{F^{\text{ad}}} \arrow[]{d}{\Psi} W\\
            V^* & W^* \arrow[]{l}{F^*}
        \end{tikzcd}
    \end{center}
    \item   Sind $\mathcal{A}$ und $\mathcal{B}$ ONB von $V$ bzw. $W$, so gilt
    \begin{align*}
        \mathcal{M}_{\mathcal{A}}^{\mathcal{B}}(F^{\ad}) = \left(\mathcal{M}_{\mathcal{B}}^{\mathcal{A}}\right)^H
    \end{align*}
    \item   $V$ und $W$ lassen sich wie folgt orthogonal Zerlegen
    \begin{align*}
        V = \Ker F \obot \Image F^{\ad} \quad \text{und} \quad W = \Ker F^{\ad} \obot \Image F
    \end{align*}
    und es gilt
    \begin{empheq}[box=\bluebase]{align*}
        \Ker(F^{\ad}) = (\Ker F)^{\bot} \quad \text{und} \quad \Ker(F^{\ad}) = (\Image F)^{\bot}
    \end{empheq}
    Ist $F$ selbstadjungiert, so gilt $V = \Ker F \obot \Image F$.
\end{enumerate}

\textbf{Bemerkung:} \quad Für unitäre $\C$-Vektorräume ist die Adjungierte auch linear, da $\Phi^{-1} \circ F^* \circ \Psi$, aber die Abbildung
\begin{align*}
    (-)^{\ad}: \Hom(V,W) \to \Hom(W,V), \quad F \mapsto F^{\ad}
\end{align*}
ist nur semilinar (d.h. $(\lambda F)^{\ad} = \overline{\lambda} F^{\ad}$, da das $\lambda$ nur über $\Phi^{-1}$ gezogen wird.

\textbf{Beispiel:} \quad $F = L_A$, $A \in M(m\times n,K)$, $\left<u,v\right>_V = u^TCv$ und $\left<w,z\right>_W = w^TDz$ mit $C,D$ symmetrisch positiv definit.
Angenommen $F^{ad} =: L_B$ existiert. Dann gilt $\forall v,w$
\begin{align*}
    \left<Av,w\right> = \left<v,Bw\right> \implies v^TA^TDw = v^TCBw\\
    \implies A^TD = CB \implies B = C^{-1}A^TD
\end{align*}

\textbf{Beispiel:} \quad $W = \{\left(a_n\right)_{n = 0}^{\infty} \big\vert a \text{ beschränkt}\}$ und definiere
\begin{align*}
    \left<\left(x_n\right)_{n = 0}^{\infty},\left(y_n\right)_{n = 0}^{\infty}\right> := \sum_{i = 0}^{\infty} \frac{x_n y_n}{n^2}
\end{align*}
Definiere $V = \{a \in W \big\vert \exists N: \forall n \geq \N a_n = 0\}$. Ist $F: V \hookrightarrow W$ die Inklusion. Angenommen $F^{ad}$ existiert. Dann wähle die Folge $w = \left(1\right)_{n = 0}^{\infty}$. Dann müsste $F^{ad}(w) \in V$. Also $\exists N \in \N, \forall n \geq N: F^{ad}(w)_n = 0$.

Wähle $v_n = \left(n^2 \delta_{nm}\right)_m \in V$. Aber wir erhalten
\begin{align*}
    \left<F(v_n),w\right> = \left<v_n,w\right> = \frac{n^2 \cdot 1}{n^2} = 1\\
    \left<v_n,F^{ad}(w)\right> = 0, \forall n \geq N
\end{align*}


\begin{proposition}{}
    Sei $V$ euklidisch/unitär und endlich dimensional, $F \in \Hom(V,W))$ sodass $F^{ad}$ exisitert. Für eine ONB $(v_{1}, \ldots, v_{n})$ von $V$ gilt
    \begin{empheq}[box=\bluebase]{align*}
        F^{ad}(w) = \sum_{i = 0}^{n} \left<w,f(v_i)\right>v_j, \quad \forall w \in W
    \end{empheq}
\end{proposition}

\textbf{Beweis:} 
\begin{align*}
    \left<b_j,F^{ad}(w)\right> = \sum_{i = 0}^{n} \left<w,f(b_i)\right> \left<b_i,b_j\right> \stackrel{ONB}{=} \overline{\left<w,f(b_j)\right>} = \left<f(b_j),w\right>
\end{align*}

\begin{proposition}{}
    Seien $\mathcal{B}, \mathcal{B}'$ ONB von $V,W$ Dann gilt
    \begin{align*}
        \mathcal{M}_{\mathcal{B}}^{\mathcal{B'}}(F^{ad}) = \left(\mathcal{M}_{\mathcal{B}'}^{\mathcal{B}}\right)^H
    \end{align*}
\end{proposition}

\textbf{Proposition:} Sei $\Phi: V \to V^*$ der Kanonische Isomorphismus $v \mapsto \left<v,-\right>$ und $\Psi: W \to W^*, w \mapsto \left<w,-\right>$.    Dann kommutiert das folgende Diagramm
\begin{center}
    \begin{tikzcd}[] %\arrow[bend right,swap]{dr}{F}
        V \arrow[swap]{d}{\Phi} & W \arrow[swap]{l}{F^{ad}} \arrow[]{d}{\Psi}\\
        V^* & W^* \arrow[]{l}{F^*}
    \end{tikzcd}
\end{center}
d.h. $\Phi \circ F^{ad} = F^* \circ \Psi$ weil
\begin{align*}
    F^* \circ \Psi(w) = F^*(\left<w,-\right>) =  \left<w,f(\cdot)\right> = \left<F^{ad}(w),-\right> = \Phi \circ F^{ad}(w)
\end{align*}


$\Image F^{ad} = (\Ker F)^{\bot}, \Ker F^{ad} = (\Image F)^{\bot}$

\begin{empheq}[box=\bluebase]{align*}
    \Image F^{ad}
\end{empheq}

\begin{definition}{Selbstadjungierte Endomorphismen}
    Sei $K = \R, \C$, $V$ ein euklidischer/unitärer $K$-Vektorraum. 
    $F: V \to V$ heisst \textbf{selbstadjungiert}, falls $F = F^{ad}$, d.h.
    \begin{align*}
        \left<f(v),w\right> = \left<v,f(w)\right>
    \end{align*}
\end{definition}
Ist $F$ ein selbstadjungierter Endomorphismus eines eukl./unitären VR $V$, so gilt:
\begin{enumerate}
    \item   Alle Eigenwerte von $F$ sind reell.
    \item   (Spektralsatz) \quad Es gibt eine ONB von $V$ aus Eigenvektoren von $F$.
    \item   Ist $v \in V$ ein Eigenvektor von $F$, so ist sind folgende Räume $F$-invariant.
    \begin{align*}
        F(\spn(v)) \subseteq \spn(v) \quad \text{und} \quad F(\spn(v)^{\bot}) \subseteq \spn(v)^{\bot} 
    \end{align*}
    Um die ONB zu bestimmen, bestimmt man Basen zu $\Ker(F - \lambda \id_V)$ und orthonormalisiert sie (z.B. mit Gram Schmidt).
    \item   Sind $\lambda_1, \ldots, \lambda_k$ die Eigenwerte von $F$, so gilt
    \begin{align*}
        V = \Eig(F;\lambda_1) \obot \cdots \obot \Eig(F;\lambda_k)
    \end{align*}
    \item   Ist $\mathcal{B}$ eine ONB von $V$, so gilt: $F$ selbstadjungiert $\Leftrightarrow \mathcal{M}_{\mathcal{B}}(F)$ symmetrisch/hermitesch. 
\end{enumerate} 
Analog für Matrizen: Sei $A \in M(n\times n,\K)$ symmetrisch/hermitesch, also $A = A^H$. Dann gilt
\begin{enumerate}
    \item   Es gibt eine orthogonale/unitäre Matrix $Q \in \mathcal{O}(n)/ \mathcal{U}(n)$ sodass $Q^TA \overline{Q} = \text{diag}(\lambda_1, \ldots \lambda_n)$ mit $\lambda_{1}, \ldots, \lambda_{n} \in \R$ Eigenwerten von $A$.\\
    
    Hat man eine ONB von $V$ aus Eigenvektoren $(v_1, \ldots, v_n)$ gefunden, so erfüllt $Q := (v_1| \cdots | v_n)$ diese Eigenschaft.
\end{enumerate}




\begin{nosatz}{Hauptachsentransformation}
    Sei $A \in M(n\times n,\K)$ symmetrisch/hermitesch und $s$ die durch $A$ beschriebene Bilinear-/Sesquilinearform auf $\K^n$, also $s(x,y) = x^T A \overline{y}$, und $F \in \End(V)$ die entsprechende selbstadjungierte Abbildung, dann gilt
    
    \begin{enumerate}
        \item	Es gibt eine ONB  $\mathcal{B} = (v_1, \ldots v_n)$ von $\K^n$ bez. des kanonischen Skalarproduktes aus Eigenvektoren von $A$, also
        \begin{align*}
            \mathcal{M}_{\mathcal{B}}(s) = \mathcal{M}_{\mathcal{B}}(F) = \begin{pmatrix}
                \lambda_1 & & 0\\
                 & \ddots & \\
                 0 & & \lambda_n
            \end{pmatrix} = D \quad \text{mit}\quad \lambda_1, \ldots \lambda_n \in \R \text{ Eigenwerte von $A$ bzw. $F$}.
        \end{align*}
        Insbesondere gibt es eine orthogonale/unitäre Matrix $Q \in \mathcal{O}(n)/ \mathcal{U}(n)$ sodass $Q^T A \overline{Q} = D$.
        \item   Es gibt eine Basis $\tilde{\mathcal{B}} = (\tilde{v}_1, \ldots, \tilde{v}_n)$ von $\K^n$, sodass 
        \begin{align*}
            \mathcal{M}_{\tilde{\mathcal{B}}}(s) = \begin{pmatrix}
                E_k & & 0\\
                & -E_l\\
                0 & & 0
            \end{pmatrix} = \tilde{D}
        \end{align*}
        Es gibt ein $S \in GL(n,\K)$ sodass $S^T A \overline{T} = \tilde{D}$.\\
        Die Zahlen $k,l$ sind eindeutig bestimmt, da sie die Anzahl positiver bzw. negativer Eigenwerte sind.
    \end{enumerate}
\end{nosatz}
\textbf{Bemerkung:} \quad   Um $\mathcal{B}$ zu erhalten, berechnet man die Eigenvektoren von $A$ und orthonormalisiert sie, um $(v_1, \ldots v_n)$ zu erhalten. Für $\tilde{\mathcal{B}}$ setzt man
\begin{align*}
    \tilde{v}_i = \left\{ \begin{array}{rcl}
        \frac{1}{\sqrt{\abs{\lambda_i}}} v_i, &\text{falls}& \lambda_i \neq 0\\
        v_i, &\text{sonst}
    \end{array} \right.
\end{align*}

\begin{satz}{Positive Definitheit}
    Sei $A \in M(n\times n,\K)$ symmetrisch/hermitesch. Dann sind äquivalent
    \begin{enumerate}
        \item   $A$ ist positiv definit, also $x^TA \overline{x} > 0$ für alle $x \neq 0 \in \K^n$
        \item   Alle Eigenwerte von $A$ sind positiv.
        \item   Es gibt ein $S \in GL(n,\K)$ sodass $A = S^HS$.
        \item   Sei $P_A(t) = (-t)^n + \alpha_{n-1} t^{n-1} + \cdots + \alpha_1t + \alpha_0 \in \R[t]$ das charakteristische Polynom von $A$, dann gilt 
        \begin{align*}
            (-1)^{n-j}\alpha_j > 0 \quad \text{für} \quad j = 0, \ldots, n-1
        \end{align*}
        \item   Die Hauptminoren der Untermatrizen $A_k \in M(k\times k,\K)$ oben links sind positiv: \quad $\det A_k > 0$ für $k = 1, \ldots n$
    \end{enumerate}
    Weil $A$ negativ definit $\Leftrightarrow -A$ positiv definit gilt auch
    \begin{align*}
        A \text{ negativ definit } \Leftrightarrow \alpha_i > 0 \quad \text{für} \quad j = 1, \ldots, n
    \end{align*}
\end{satz}




\begin{nosatz}{Trägheitssatz von Sylvester}
    Sei $q$ die zur symmerische Bilinearform $s$ gehörende quadratische Form gegeben durch $q(v) = s(v,v) = v^TAv$. Dann existiert eine Zerlegung $V = V_+ \oplus V_- \oplus V_0$ sodass 
    \begin{align*}
        q(v) = \begin{cases}
            > 0, \forall v \in V_+\\
            < 0, \forall v \in V_-\\
            = 0, \forall v \in V_0
        \end{cases}
    \end{align*}
    Die Zerlegung ist nicht eindeutig bestimmt, aber die dimensionen der UVR ist unabhängig von der Zerlegung. Beweis mit Hauptachsentransformation.
    Das tupel $(\dim V_+, \dim V_-)$ ist die \textbf{Signatur} von $q$.
\end{nosatz}

\begin{nosatz}{Orthogonalisierungssatz}
    Sei $V$ ein $K$-Vektorraum, sodass $char(K) \neq 2$. Sei $s: V \times V \to K$ eine symmetrische Bilinearform. Dann existiert eine Basis $(b_{1}, \ldots, b_{n})$ von $V$ sodass $s(b_i,b_j) = 0, \forall i \neq j$.
    Die quadratische Form $q_S: V \to K$ ist dann
    \begin{align*}
        q_s \left(
            \sum_{i = 1}^{n} x_i b_i
        \right) = \sum_{i = 1}^{n} q(b_i)x_i^2
    \end{align*}
\end{nosatz}

\textbf{Beispiel:} Seien $A,B$ symmetrische reelle Matrizen, $A$ pos. definit. z.z: $\exists S \in GL(n,\R)$, sodass $S^TAS$ und $S^TBS$ diagonal sind.

\textbf{Beweis:} \quad Die Cholesky Zerlegung gibt uns $A = R^TR$, wobei $R$ obere Dreiecksmatrix, $R$ invertierbar ist.
Definiere $C = {R^{-1}}^TBR^{-1}$ symmetrisch. Wir wissen es gibt eine Orthogonale Matrix $Q \in \mathcal{O}(n)$, sodass $Q^TCQ$ diagonal ist.
Setze dann $S = R^{-1}Q$. Dann sind 
\begin{align*}
    S^TAS = Q^T{R^{-1}}^TR^TRR^{-1}Q = Q^TQ = E_n\\
    S^TBS = Q^T{R^{-1}}^TBR^{-1}Q = Q^TCQ = D
\end{align*}

\begin{definition}{Normale Endomorphismen/Matrizen}
    Ein $f \in \End(V)$ heisst \textbf{normal}, falls $f \circ f^{ad} = f^{ad} \circ f$.

    Selbstadjungierte und orthogonale/unitäre Endmorphismen sind normal.

    Eine Matrix $A \in M(n\times n,K)$ heisst \textbf{normal}, falls $A^HA = AA^H$
\end{definition}


\textbf{Beispiel:} \quad \begin{itemize}
    \item   Diagonalmatrizen und Schiefsymmetrische Matrizen sind normal.
    \item   $V = \{f \in C^\infty(\R) \big\vert \forall x \in \R \big\vert f(x + 2\pi) = f(x)\}$. Nehme das Standardskalarprodukt $\left<f,g\right> = \int_{0}^{2\pi} f(x) \overline{g(x)} dx$.  Die Ableitung $D: V \to V, D(f) = \frac{df}{dx}$. Dann ist $D^{ad} = -D$ Also ist $D$ normal.
    \begin{align*}
        \left<Df,g\right> = \int_{0}^{2\pi} f'(x)\overline{g(x)}dx = [f(x) \overline{g(x)}]_{0}^{2\pi} - \int_{0}^{2\pi} f(x) \overline{g'(x)}dx = -\left<f,Dg\right>
    \end{align*}
\end{itemize}

\begin{nosatz}{}
    Sei $f$ normal, $\dim V < \infty$.
    Dann gilt $\Ker f^{ad} = \Ker f$ und $\Image f^{ad} = \Image f$
\end{nosatz}
\textbf{Korollar:} \quad $f$ normal $\implies \Eig(f;\lambda) = \Eig(f^{ad};\overline{\lambda})$

\begin{nosatz}{Spektralsatz}
    Sei $V$ ein eindlich dimensionaler unitärer Vektorraum. Dann gilt 
    \begin{align*}
        f \text{ normal } \Leftrightarrow \exists ONB \text{ aus Eigenvektoren von $f$}
    \end{align*}
\end{nosatz}


Alle Eigenwerte $\lambda$ von orthogonalen/unitären  selbstadjungierten Endomorphismen haben $\abs{\lambda} = 1$.

\textbf{Beispiel} \quad $f,g$ normale Endomorphismen eines unitären V
$K$-Vektorraum V, sodass $f \circ g = g \circ f$. Dann gilt $f^{ad} \circ g = g \circ f^{ad}$ und $f + g, fg$ sind normal.


\begin{nosatz}{Singulärwertzerlegung}
    $\forall A \in M(m\times n,K), K = \R, \C$ mit $r = \rang A$ $\exists U \in \mathcal{O}(m)/ \mathcal{U}(m), V \in \mathcal{O}(n)/ \mathcal{U}(n)$ und ein $D = diag(\sigma_{1}, \ldots, \sigma_{r}, 0, \ldots 0)$ sodass $A = UDV^H$.

    Die Singulärwerte $\sigma_{1}, \ldots, \sigma_{r}$ sind unabhängig von $U,V$.

    \textbf{Alternativ:} \quad $\tilde{U} \in M(m\times r,K)$ und $\tilde{V} \in M(n\times r,K), \tilde{D} = diag(\sigma_{1}, \ldots, \sigma_{r}) \in M(r\times n,K)$.
\end{nosatz}

\begin{rezept}{Singulärwertzerlegung}
    \begin{enumerate}[{(}i{)}]
        \item   $\sigma_1^2 \geq \ldots \geq \sigma_r^2$ sind die Eigenwerte von $A^HA$, bzw. $AA^H$ inkl. Nullen.
        \item   Berechne $\tilde{V} = (v_1| \ldots | v_r)$ als ONB von $\R^n$ aus Eigenvektoren von $A^HA$.
        \item   Berechne $\tilde{U} = (u_1| \ldots | u_r)$ als ONB von $\R^m$ aus Eigenvektoren von $AA^H$
        \item   Ergänze $(v_{1}, \ldots, v_{r}, \ldots v_n) = V$ und $(u_{1}, \ldots, u_{r}, \ldots u_m) = U$ zu ONB. (Gram-schmidt, Kreuzprodukt)
        \item   $A = U D V^H$ 
    \end{enumerate}
\end{rezept}

\begin{nosatz}{}
    Sei $F \in \Hom(V,W)$ und $\dim V, \dim W < \infty$. Dann existieren ONBs $\mathcal{A}, \mathcal{B}$ von $V$ und $W$, sodass $\mathcal{M}_{\mathcal{B}}^{\mathcal{A}}(F) = D$ in obiger Diagonalform.
\end{nosatz}

\begin{definition}{Spezielle Normen}
    Für $A \in M(m\times n,K)$ ist die \textbf{Frobeniusnorm} definiert durch
    \begin{align*}
        \Norm{A}_F := \sqrt{
            \sum_{i = 1}^{n} \sum_{j = 1}^{n} \abs{a_{ij}}^2
        } = \sqrt{\trace(A^TA)}
    \end{align*}
    und die \textbf{Spektralnorm} durch
    \begin{align*}
        \Norm{A}_2 :=  \sigma_1 = \max_{\underset{\Norm{x} = 1}{x \in K^n}} \Norm{A}x_2
    \end{align*}
    Und es gilt für alle $U,V \in \mathcal{U}(n)$ bzw. $\mathcal{U}(m)$ dass
    \begin{align*}
        \Norm{UAV}_2 = \Norm{A}_2, \quad \Norm{UAV}_F = \Norm{A}_F
    \end{align*}
\end{definition}

\begin{satz}{Überbestimmte LGS}
    Für ein überbestimmtes LGS $Ax = b$ ist der Fehler $\Norm{Ax - b}_2$ genau dann minimiert, wenn $A^HAx = A^Hb$. Für $A = \tilde{U}\tilde{D} \tilde{V}^H$ ist dies gegeben durch $x = \tilde{V} \tilde{D}^{-1}\tilde{U}^Hb$.

    Die \textbf{Pseudoinverse} von $A$ ist $\hat{A} := \tilde{V} \tilde{D}^{-1}\tilde{U}^{H}$. Ist $A$ invertierbar, so ist $\hat{A} = A^{-1}$
\end{satz}

\begin{satz}{Eckart-Young-Mirsky}
    Sei $A = UDV^{H}$ und setze $D_k = diag(\sigma_{1}, \ldots, \sigma_{k}, 0, \ldots 0)$, $A_k := UD_kV^{H}$. So gilt für jede Matrix $B$ mit Rang höchstens $k$ dass 
    \begin{align*}
        \Norm{A - B}_F \geq \Norm{A - A_k}_F = \sqrt{\sum_{j = k+1}^{r}\sigma_j^2} \quad \text{und} \quad \Norm{A - B}_2 \geq \Norm{A - A_k}_2 = \sigma_{k+1}
    \end{align*}
\end{satz}

Sei $A  \in M(m\times n,K)$ und $A = UDV^{H}$. Setze $R_0 := UV^{H}$  Dann ist für alle $R \in \mathcal{U}(n)$ dass $\Norm{A-R}_F \geq \Norm{A - R_0}_F$

$\sigma \in \R$ ist genau dann ein Singulärwert, wenn $\exists v \in V, w \in W$ sodass $Av = \sigma w$ und $A^Tw  \sigma v$. Da $AA^Tv = \sigma^2 w$


